{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "608a2d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.Container {width:85% !important;}\n",
       "div.CodeMirror {font-family:나눔바른펜; font-size:13pt; line-height : 140%;}\n",
       "div.output_area pre {font-family:나눔바른펜; font-size:13pt; line-height : 140%; font-weight : bold;}\n",
       "div.output_wrapper pre {font-family:나눔바른펜; font-size:13pt; line-height : 140%;}\n",
       "div.input {font-family:나눔바른펜; font-size:13pt;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.Container {width:85% !important;}\n",
    "div.CodeMirror {font-family:나눔바른펜; font-size:13pt; line-height : 140%;}\n",
    "div.output_area pre {font-family:나눔바른펜; font-size:13pt; line-height : 140%; font-weight : bold;}\n",
    "div.output_wrapper pre {font-family:나눔바른펜; font-size:13pt; line-height : 140%;}\n",
    "div.input {font-family:나눔바른펜; font-size:13pt;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89eca25",
   "metadata": {},
   "source": [
    "<b><font color = \"red\" size = \"6\">ch01. NLTK 자연어 처리 패키지</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4668eeaa",
   "metadata": {},
   "source": [
    "# 1절. NLTK 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f38d4997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf7f239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e521d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35812c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 말뭉치 리스트\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b100398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CH\n"
     ]
    }
   ],
   "source": [
    "emma = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
    "\n",
    "print(emma[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be1b47a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 수 : 7493\n",
      "'It was on the wedding-day\\nof this beloved friend that Emma first sat in mournful thought\\nof any continuance.'\n"
     ]
    }
   ],
   "source": [
    "# 문장 단위로 나눠보기 - sent_tokenize() : list로 반환\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokens = sent_tokenize(emma)\n",
    "\n",
    "print('문장 수 :', len(sent_tokens))\n",
    "print(\"%r\" % (sent_tokens[10]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9976e276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.']\n"
     ]
    }
   ],
   "source": [
    "# 단어 단위로 쪼갠 list 반환 - word_tokenize()\n",
    "from nltk.tokenize import word_tokenize\n",
    "print( word_tokenize(sent_tokens[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bec19aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Emma', 'by', 'Jane', 'Austen', '1816', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', 'handsome', 'clever', 'and', 'rich', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', 'and', 'had', 'lived', 'nearly', 'twenty', 'one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her']\n"
     ]
    }
   ],
   "source": [
    "# regexpTokenizer 클래스 - 토큰화할 때 정규표현식을 이용할 수 있다.\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "ret = RegexpTokenizer('[\\w]+')\n",
    "\n",
    "print(ret.tokenize(sent_tokens[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de855a75",
   "metadata": {},
   "source": [
    "# 2절. 형태소 분석\n",
    "-  형태소 : 의미가 있는 가장 작은 말의 단위<br><br>\n",
    "- cf. 자연어 처리의 기본은 형태소 분석과 품사 태깅\n",
    "    - 어간 추출(Stemming)\n",
    "    - 원형 복원(Lemmatizing)\n",
    "    - 품사 태깅(Part of Speech Tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c28722f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('send', 'cook', 'file')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [ 'sending', 'cooking', 'files', 'lives', 'crying', 'dying' ]\n",
    "\n",
    "# 어간 추출(1) : PorterStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "pst = PorterStemmer()\n",
    "pst.stem(words[0]), pst.stem(words[1]), pst.stem(words[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5f18fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['send', 'cook', 'file', 'live', 'cri', 'die']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ pst.stem(w) for w in words ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e906db0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['send', 'cook', 'fil', 'liv', 'cry', 'dying']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어간 추출(2) : LanscasterStemmer\n",
    "# 어간 추출 기능 중 제일 많이 쓰임\n",
    "from nltk.stem import LancasterStemmer\n",
    "lst = LancasterStemmer()\n",
    "[ lst.stem(w) for w in words ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e247df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['send', 'cook', 'files', 'lives', 'cry', 'dy']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어간 추출(3) : RegexpStemmer\n",
    "from nltk.stem import RegexpStemmer\n",
    "rst = RegexpStemmer('ing')\n",
    "[ rst.stem(w) for w in words ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dd2d120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bel', 'cook']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어간 추출을 할 경우 의미가 달라질 수 있어 원형복원을 한다.\n",
    "word2 = [ 'belives', 'cooking' ]\n",
    "[lst.stem(w) for w in word2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6c4d07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['belives', 'cooking']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원형 복원\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    "[ wl.lemmatize(w) for w in word2 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af58046d",
   "metadata": {},
   "source": [
    "## 품사 태깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e6f9fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'was', 'on', 'the', 'wedding-day', 'of', 'this', 'beloved', 'friend', 'that', 'Emma', 'first', 'sat', 'in', 'mournful', 'thought', 'of', 'any', 'continuance', '.']\n",
      "\n",
      "품사 태깅 결과\n",
      " [('It', 'PRP'), ('was', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('wedding-day', 'NN'), ('of', 'IN'), ('this', 'DT'), ('beloved', 'VBN'), ('friend', 'NN'), ('that', 'WDT'), ('Emma', 'NNP'), ('first', 'RB'), ('sat', 'VBD'), ('in', 'IN'), ('mournful', 'JJ'), ('thought', 'NN'), ('of', 'IN'), ('any', 'DT'), ('continuance', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "taged_list = pos_tag(word_tokenize(sent_tokens[10]))\n",
    "\n",
    "print(word_tokenize(sent_tokens[10]))\n",
    "print('\\n품사 태깅 결과\\n', taged_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c3b3d6",
   "metadata": {},
   "source": [
    "# 퀴즈 : emma 소설안에서\n",
    "<pre>\n",
    "1. 특수문자가 들어가지 않은 3글자이상의 단어만 추출해서 품사 태깅\n",
    "2. \"Emma\" 단어가 몇 번 등장하는지, 품사 태깅이 어떤 품사들도 되어 있는지 모두 출력\n",
    "3. 내가 원하는 품사(명사)의 단어만 뽑아 등장하는 명사의 종류 개수를 출력\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588b3928",
   "metadata": {},
   "source": [
    "## 1번문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2319047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9242df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74268156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7bacb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5d38f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "246px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "429px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
